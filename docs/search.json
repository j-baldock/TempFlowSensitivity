[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stream Temperature by Flow",
    "section": "",
    "text": "1 Introduction\nThis book provides a visual story of efforts to quantify the influence of streamflow on water temperature in small, headwater streams. All data was collected as part of the USGS EcoDrought project, funded by the USGS Ecosystems Mission Area, USGS Water Mission Area, and the BLM. Our approach generally follows that of Letcher et al. (2016).\nAccess the GitHub repo here: https://github.com/j-baldock/TempFlowSensitivity.git\nThis information is preliminary or provisional and is subject to revision. It is being provided to meet the need for timely best science. The information has not received final approval by the U.S. Geological Survey (USGS) and is provided on the condition that neither the USGS nor the U.S. Government shall be held liable for any damages resulting from the authorized or unauthorized use of the information.\nProject team: Jeff Baldock, Jenn Fair, Ben Letcher, Robert Al-Chokhachy, Jason Dunham, Clint Muhlfeld\n\n\nSession Information\n\n\n\n\nCodesessionInfo()\n\nR version 4.5.1 (2025-06-13 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 22631)\n\nMatrix products: default\n  LAPACK version 3.12.1\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Denver\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.5.1    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.5.1       htmltools_0.5.8.1 rstudioapi_0.17.1 rmarkdown_2.29   \n [9] knitr_1.50        jsonlite_2.0.0    xfun_0.53         digest_0.6.37    \n[13] rlang_1.1.6       evaluate_1.0.5",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "DataViz.html",
    "href": "DataViz.html",
    "title": "\n2  Visualize Data\n",
    "section": "",
    "text": "2.1 Site information\nCodesiteinfo &lt;- read_csv(\"data/EcoDrought_SiteInformation.csv\")\ndatatable(siteinfo)\n\n\n\n\nCodesiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualize Data</span>"
    ]
  },
  {
    "objectID": "DataViz.html#flow-and-temp-data",
    "href": "DataViz.html#flow-and-temp-data",
    "title": "\n2  Visualize Data\n",
    "section": "\n2.2 Flow and temp data",
    "text": "2.2 Flow and temp data\nLoad data\n\nCodedat &lt;- read_csv(\"data/EcoDrought_FlowTempData_DailyWeekly.csv\")\ndat\n\n# A tibble: 202,014 × 31\n   station_no site_name      site_id basin   subbasin region   lat  long elev_ft\n   &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 2 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 3 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 4 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 5 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 6 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 7 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 8 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 9 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n10 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n# ℹ 202,004 more rows\n# ℹ 22 more variables: area_sqmi &lt;dbl&gt;, designation &lt;chr&gt;, date &lt;date&gt;,\n#   DischargeReliability &lt;dbl&gt;, TempReliability &lt;dbl&gt;, flow_mean &lt;dbl&gt;,\n#   flow_min &lt;dbl&gt;, flow_max &lt;dbl&gt;, tempc_mean &lt;dbl&gt;, tempc_min &lt;dbl&gt;,\n#   tempc_max &lt;dbl&gt;, flow_mean_filled &lt;dbl&gt;, flow_mean_cms &lt;dbl&gt;,\n#   flow_mean_filled_cms &lt;dbl&gt;, area_sqkm &lt;dbl&gt;, Yield_mm &lt;dbl&gt;,\n#   Yield_filled_mm &lt;dbl&gt;, flow_mean_7 &lt;dbl&gt;, flow_mean_filled_7 &lt;dbl&gt;, …\n\n\nUnique basins\n\nCodeunique(dat$basin)\n\n[1] \"Flathead\"       \"West Brook\"     \"Donner Blitzen\" \"Paine Run\"     \n[5] \"Piney River\"    \"Staunton River\" \"Shields River\"  \"Snake River\"   \n\n\n\n2.2.1 View daily temp\n\n\nWest Brook\nPaine Run\nStaunton River\nFlathead River\nYellowstone River\nSnake River\nDonner und Blitzen River\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.2 View daily flow\n\n\nWest Brook\nPaine Run\nStaunton River\nFlathead River\nYellowstone River\nSnake River\nDonner und Blitzen River",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualize Data</span>"
    ]
  },
  {
    "objectID": "DataViz.html#daymet-data",
    "href": "DataViz.html#daymet-data",
    "title": "\n2  Visualize Data\n",
    "section": "\n2.3 Daymet data",
    "text": "2.3 Daymet data\nTrim siteinfo to sites with temp/flow data\n\nCodesiteinfo_sub &lt;- siteinfo %&gt;% filter(site_name %in% unique(dat$site_name))\n\n\nDownload Daymet daily air temperature data for each site (point locations)\n\nCodeclimlist &lt;- vector(\"list\", length = dim(siteinfo_sub)[1])\nfor (i in 1:dim(siteinfo_sub)[1]) {\n  clim &lt;- download_daymet(site = siteinfo_sub$site_name[i], lat = siteinfo_sub$lat[i], lon = siteinfo_sub$long[i], start = 2010, end = 2024, internal = T)\n  climlist[[i]] &lt;- tibble(clim$data) %&gt;% \n    mutate(air_temp_mean = (tmax..deg.c. + tmin..deg.c.)/2, \n           date = as.Date(paste(year, yday, sep = \"-\"), \"%Y-%j\"),\n           site_name = siteinfo_sub$site_name[i]) %&gt;%\n    select(12,2,11,10,4,6,3,5) %&gt;% rename(precip_mmday = 5, swe_kgm2 = 6, daylength_sec = 7, shortrad_wm2 = 8)\n  print(i)\n}\nclimdf &lt;- do.call(rbind, climlist)\nwrite_csv(climdf, \"data/Daymet_daily.csv\")\n\n\nRe-load Daymet climate data\n\nCodeclimdf &lt;- read_csv(\"data/Daymet_daily.csv\")\n\n\nPlot example Daymet time series data (2020-2025, Avery Brook, MA)\n\nCodeggarrange(climdf %&gt;% filter(site_name == \"Avery Brook\", year(date) &gt;= 2020) %&gt;% ggplot(aes(x = date, y = air_temp_mean)) + geom_line(),\n          climdf %&gt;% filter(site_name == \"Avery Brook\", year(date) &gt;= 2020) %&gt;% ggplot(aes(x = date, y = precip_mmday)) + geom_line(),\n          climdf %&gt;% filter(site_name == \"Avery Brook\", year(date) &gt;= 2020) %&gt;% ggplot(aes(x = date, y = swe_kgm2)) + geom_line(),\n          climdf %&gt;% filter(site_name == \"Avery Brook\", year(date) &gt;= 2020) %&gt;% ggplot(aes(x = date, y = daylength_sec)) + geom_line(),\n          climdf %&gt;% filter(site_name == \"Avery Brook\", year(date) &gt;= 2020) %&gt;% ggplot(aes(x = date, y = shortrad_wm2)) + geom_line(),\n          ncol = 1)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualize Data</span>"
    ]
  },
  {
    "objectID": "Breakpoints.html",
    "href": "Breakpoints.html",
    "title": "\n3  Breakpoints\n",
    "section": "",
    "text": "3.1 Data\nSite information\nCodesiteinfo &lt;- read_csv(\"data/EcoDrought_SiteInformation.csv\")\ndatatable(siteinfo)\n\n\n\n\nCodesiteinfo_sp &lt;- st_as_sf(siteinfo, coords = c(\"long\", \"lat\"), crs = 4326)\nmapview(siteinfo_sp, zcol = \"designation\")\nLoad flow and temp data\nCodedat &lt;- read_csv(\"data/EcoDrought_FlowTempData_DailyWeekly.csv\")\ndat\n\n# A tibble: 202,014 × 31\n   station_no site_name      site_id basin   subbasin region   lat  long elev_ft\n   &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 2 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 3 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 4 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 5 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 6 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 7 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 8 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n 9 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n10 12355347   Big Creek NWIS BIG     Flathe… Big Cre… Flat    48.6 -114.   3528.\n# ℹ 202,004 more rows\n# ℹ 22 more variables: area_sqmi &lt;dbl&gt;, designation &lt;chr&gt;, date &lt;date&gt;,\n#   DischargeReliability &lt;dbl&gt;, TempReliability &lt;dbl&gt;, flow_mean &lt;dbl&gt;,\n#   flow_min &lt;dbl&gt;, flow_max &lt;dbl&gt;, tempc_mean &lt;dbl&gt;, tempc_min &lt;dbl&gt;,\n#   tempc_max &lt;dbl&gt;, flow_mean_filled &lt;dbl&gt;, flow_mean_cms &lt;dbl&gt;,\n#   flow_mean_filled_cms &lt;dbl&gt;, area_sqkm &lt;dbl&gt;, Yield_mm &lt;dbl&gt;,\n#   Yield_filled_mm &lt;dbl&gt;, flow_mean_7 &lt;dbl&gt;, flow_mean_filled_7 &lt;dbl&gt;, …\nAdjust/filter sites\nCodedat &lt;- dat %&gt;% \n  # combine sites co-located in space, but not in time (same location but different names depending on year)\n  mutate(site_name = dplyr::recode(site_name, \n                                   \"Leidy Creek Mouth NWIS\" = \"Leidy Creek Mouth\", \n                                   \"SF Spread Creek Lower NWIS\" = \"SF Spread Creek Lower\", \n                                   \"Dugout Creek NWIS\" = \"Dugout Creek\", \n                                   \"Shields River ab Smith NWIS\" = \"Shields River Valley Ranch\")) %&gt;%\n  # drop sites co-located in space and in time (entirely redundant)\n  filter(!site_name %in% c(\"Avery Brook NWIS\", \"West Brook 0\", \"BigCreekMiddle\")) %&gt;%\n  # drop Piney River (no within basin replication)\n  filter(basin != \"Piney River\") %&gt;%\n  # drop Wounded Buck (no temperature data)\n  filter(basin != \"Piney River\") %&gt;%\n  # drop some big Gs\n  filter(!site_name %in% c(\"South River Conway NWIS\", \n                           \"North Fork Flathead River NWIS\",        \n                           \"Shields River nr Livingston NWIS\"   \n                           #\"Donner Blitzen River nr Frenchglen NWIS\",    \n                           #\"Pacific Creek at Moran NWIS\", \n                           )) %&gt;%                                             \n  group_by(site_name, basin, date) %&gt;%\n  summarize(flow_mean = mean(flow_mean),\n            tempc_mean = mean(tempc_mean),\n            tempc_min = mean(tempc_min),\n            tempc_max = mean(tempc_max),\n            Yield_mm = mean(Yield_mm)) %&gt;%\n  ungroup() %&gt;%\n  left_join(siteinfo %&gt;% select(site_name, lat, long, area_sqmi, elev_ft))\nCut out all days with missing temp records\nCodedat &lt;- dat %&gt;% filter(!is.na(tempc_mean))\ndat\n\n# A tibble: 100,229 × 12\n   site_name  basin date       flow_mean tempc_mean tempc_min tempc_max Yield_mm\n   &lt;chr&gt;      &lt;chr&gt; &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Avery Bro… West… 2020-01-08      5.96     0.594      0.111     1.11      1.99\n 2 Avery Bro… West… 2020-01-09      4.81     0.0336     0         0.111     1.61\n 3 Avery Bro… West… 2020-01-10      4.88     0.363      0         0.778     1.63\n 4 Avery Bro… West… 2020-01-11      6.43     1.77       0.778     2.39      2.15\n 5 Avery Bro… West… 2020-01-12     21.2      2.81       2.11      3.78      7.08\n 6 Avery Bro… West… 2020-01-13     14.3      1.92       1.56      2.22      4.78\n 7 Avery Bro… West… 2020-01-14      9.88     2.34       1.89      2.83      3.30\n 8 Avery Bro… West… 2020-01-15      9.68     2.66       2.11      3.06      3.23\n 9 Avery Bro… West… 2020-01-16      9.60     1.82       1.11      2.39      3.20\n10 Avery Bro… West… 2020-01-17      7.92     0.0463    -0.111     1.11      2.64\n# ℹ 100,219 more rows\n# ℹ 4 more variables: lat &lt;dbl&gt;, long &lt;dbl&gt;, area_sqmi &lt;dbl&gt;, elev_ft &lt;dbl&gt;\nFill missing dates using fasstr\nCodedat &lt;- fill_missing_dates(dat, dates = date, groups = site_name, pad_ends = TRUE)\ndat\n\n# A tibble: 171,661 × 12\n   site_name  basin date       flow_mean tempc_mean tempc_min tempc_max Yield_mm\n   &lt;chr&gt;      &lt;chr&gt; &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Avery Bro… &lt;NA&gt;  2020-01-01     NA       NA         NA        NA        NA   \n 2 Avery Bro… &lt;NA&gt;  2020-01-02     NA       NA         NA        NA        NA   \n 3 Avery Bro… &lt;NA&gt;  2020-01-03     NA       NA         NA        NA        NA   \n 4 Avery Bro… &lt;NA&gt;  2020-01-04     NA       NA         NA        NA        NA   \n 5 Avery Bro… &lt;NA&gt;  2020-01-05     NA       NA         NA        NA        NA   \n 6 Avery Bro… &lt;NA&gt;  2020-01-06     NA       NA         NA        NA        NA   \n 7 Avery Bro… &lt;NA&gt;  2020-01-07     NA       NA         NA        NA        NA   \n 8 Avery Bro… West… 2020-01-08      5.96     0.594      0.111     1.11      1.99\n 9 Avery Bro… West… 2020-01-09      4.81     0.0336     0         0.111     1.61\n10 Avery Bro… West… 2020-01-10      4.88     0.363      0         0.778     1.63\n# ℹ 171,651 more rows\n# ℹ 4 more variables: lat &lt;dbl&gt;, long &lt;dbl&gt;, area_sqmi &lt;dbl&gt;, elev_ft &lt;dbl&gt;\nUnique basins\nCodeunique(dat$basin)\n\n[1] NA               \"West Brook\"     \"Flathead\"       \"Shields River\" \n[5] \"Donner Blitzen\" \"Snake River\"    \"Paine Run\"      \"Staunton River\"\nBind climate data to flow-temp data\nCodeclimdf &lt;- read_csv(\"data/Daymet_daily.csv\")\ndat &lt;- dat %&gt;% left_join(climdf)\nPlot an example air (orange) and water (blue) temperature time series\nCodedat %&gt;% filter(site_name == \"BigCreekLower\") %&gt;% #select(date, tempc_mean, air_temp_mean) %&gt;% \n  ggplot() + \n  geom_line(aes(x = date, y = air_temp_mean), color = \"darkorange\") + \n  geom_line(aes(x = date, y = tempc_mean), color = \"blue\") +\n  theme_bw() + ylab(\"temperature (deg C)\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Breakpoints</span>"
    ]
  },
  {
    "objectID": "Breakpoints.html#data",
    "href": "Breakpoints.html#data",
    "title": "\n3  Breakpoints\n",
    "section": "",
    "text": "Combine co-located sites that do not overlap in time.\nDrop co-located sites that do overlap in time.\nDrop certain big Gs. NOTE: only drop big Gs on very big rivers that are clearly outside of our domain for temp/flow modeling (NF Flathead, Yellowstone, Shields, South River Conway, etc), but retain those on smaller rivers (Pacific Creek, Donner Blitzen)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Breakpoints</span>"
    ]
  },
  {
    "objectID": "Breakpoints.html#calculate-breakpoints",
    "href": "Breakpoints.html#calculate-breakpoints",
    "title": "\n3  Breakpoints\n",
    "section": "\n3.2 Calculate breakpoints",
    "text": "3.2 Calculate breakpoints\nPrep data\n\nCode# Calculate temperature index. Add small # to avoid infinity\ndat_index &lt;- dat %&gt;% \n  mutate(index = (tempc_mean - air_temp_mean) / (tempc_mean + 0.00000001),\n         year = year(date)) %&gt;%\n  filter(!is.na(yday))\n\n# Define list of sites\nsiteList &lt;- unique(dat_index$site_name)\n\n# Order by group and date\ndat_index &lt;- dat_index[order(dat_index$site_name, dat_index$year, dat_index$yday),]\n\n# For checking the order of e\ndat_index$count &lt;- 1:length(dat_index$year)\n\n# Define the site/year ID\ndat_index$siteYear &lt;- paste(dat_index$site_name, dat_index$year, sep = '_')\n\n# Maintain order\ndat_index &lt;- dat_index[order(dat_index$count),]\n\ndat_index\n\n# A tibble: 167,535 × 22\n   site_name  basin date       flow_mean tempc_mean tempc_min tempc_max Yield_mm\n   &lt;chr&gt;      &lt;chr&gt; &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Avery Bro… &lt;NA&gt;  2020-01-01     NA       NA         NA        NA        NA   \n 2 Avery Bro… &lt;NA&gt;  2020-01-02     NA       NA         NA        NA        NA   \n 3 Avery Bro… &lt;NA&gt;  2020-01-03     NA       NA         NA        NA        NA   \n 4 Avery Bro… &lt;NA&gt;  2020-01-04     NA       NA         NA        NA        NA   \n 5 Avery Bro… &lt;NA&gt;  2020-01-05     NA       NA         NA        NA        NA   \n 6 Avery Bro… &lt;NA&gt;  2020-01-06     NA       NA         NA        NA        NA   \n 7 Avery Bro… &lt;NA&gt;  2020-01-07     NA       NA         NA        NA        NA   \n 8 Avery Bro… West… 2020-01-08      5.96     0.594      0.111     1.11      1.99\n 9 Avery Bro… West… 2020-01-09      4.81     0.0336     0         0.111     1.61\n10 Avery Bro… West… 2020-01-10      4.88     0.363      0         0.778     1.63\n# ℹ 167,525 more rows\n# ℹ 14 more variables: lat &lt;dbl&gt;, long &lt;dbl&gt;, area_sqmi &lt;dbl&gt;, elev_ft &lt;dbl&gt;,\n#   yday &lt;dbl&gt;, air_temp_mean &lt;dbl&gt;, precip_mmday &lt;dbl&gt;, swe_kgm2 &lt;dbl&gt;,\n#   daylength_sec &lt;dbl&gt;, shortrad_wm2 &lt;dbl&gt;, index &lt;dbl&gt;, year &lt;dbl&gt;,\n#   count &lt;int&gt;, siteYear &lt;chr&gt;\n\n\nGet the moving average of the temp index for each site and add to data frame\n\nCode# Set frame sizefor moving mean, which is centered by default\nwindow &lt;- 10\n\n# Number of sites\nnSites &lt;- length(siteList)\n\n# Unique site and year combos \nsiteYearCombos &lt;- unique(dat_index[,c('site_name','year')])\n\n# Add columns for moving mean and sd\ndat_index$movingMean &lt;- NA\n\n# Loop through site/year combinations calculating moving means\nfor (i in 1:nrow(siteYearCombos)){\n  # Status\n  # print(c(i,as.character(siteYearCombos$site_name[i]), siteYearCombos$year[i], i/nrow(siteYearCombos)))\n  # Index current site/year\n  currSite &lt;- which(dat_index$site_name == as.character(siteYearCombos$site_name[i]) & dat_index$year == siteYearCombos$year[i] )\n  # Only calculate for sites with enough data\n  if(length(currSite) &gt;= window){currMean &lt;-  rollapply(dat_index$index[currSite], width = window, fill = NA, mean)} else(currMean &lt;- NA)\n  # Add to main dataframe\n  dat_index$movingMean[currSite] &lt;- currMean\n}\n\n# Maintain order\ndat_index &lt;- dat_index[order(dat_index$count),]\n\nwrite_csv(dat_index, \"data/EcoDrought_FlowTempData_DailyWeekly_clean.csv\")\n\n\nCreate the breaks data frame\n\nCode# Define breakpoint time period and range for tempIndex\nbeginningDayForCI &lt;- 125\nendingDayForCI &lt;- 275\nloCI &lt;- 0.001\nhiCI &lt;- 0.999\n\nfor ( i in 1:nrow(siteYearCombos)){\n  # Print status\n  #print(i)\n  # Index sites, years, and HUCs\n  tempBreaks &lt;- data.frame( year  = as.numeric  (siteYearCombos$year[i]),\n                            site_name  = as.character(siteYearCombos$site_name[i]),\n                           # HUC12 = as.character(unique(e$HUC12[which(e$site == siteYearCombos$site[i])])),\n                            #HUC8  = as.character(unique(e$HUC8 [which(e$site == siteYearCombos$site[i])])),\n                            #HUC4  = as.character(unique(e$HUC4 [which(e$site == siteYearCombos$site[i])])),\n                            quantileLo = NA,\n                            quantileHi = NA)\n  \n  # Calculate the tempindex quantiles\n  tmp &lt;- dat_index[dat_index$site_name == siteYearCombos$site_name[i] & dat_index$year %in% siteYearCombos$year[i] & dat_index$yday %in% beginningDayForCI:endingDayForCI, 'index']\n  if (any(!is.na(tmp))){\n    TIQ &lt;- quantile(tmp, probs = c(loCI,0.5,hiCI), na.rm = TRUE)\n    \n    # High and low quantiles\n    tempBreaks$quantileLo &lt;- TIQ[1]\n    tempBreaks$quantileHi &lt;- TIQ[3]\n  }\n  \n  # Add current site to \"breaks\"\n  if ( i == 1 ) { breaks &lt;- tempBreaks } else( breaks &lt;- rbind(breaks, tempBreaks))\n  \n} \n\n# Add columns used later\nbreaks$springBPComplete &lt;- FALSE\nbreaks$fallBPComplete &lt;- FALSE\nbreaks$springOrFallBPComplete &lt;- FALSE\nbreaks$springBP &lt;- NA\nbreaks$fallBP   &lt;- NA\n\nhead(breaks)\n\n  year     site_name quantileLo quantileHi springBPComplete fallBPComplete\n1 2020   Avery Brook -0.4928280  0.4245787            FALSE          FALSE\n2 2021   Avery Brook -0.4853836  0.2876319            FALSE          FALSE\n3 2022   Avery Brook -0.4425745  0.1521084            FALSE          FALSE\n4 2023   Avery Brook -0.4431010  0.2761850            FALSE          FALSE\n5 2024   Avery Brook -0.4147228  0.0801055            FALSE          FALSE\n6 2017 BigCreekLower -0.4135217  0.7688442            FALSE          FALSE\n  springOrFallBPComplete springBP fallBP\n1                  FALSE       NA     NA\n2                  FALSE       NA     NA\n3                  FALSE       NA     NA\n4                  FALSE       NA     NA\n5                  FALSE       NA     NA\n6                  FALSE       NA     NA\n\n\nUse runs analysis of the movingMean to define spring and fall breakpoints:\n\nCode# Set range (dOY) and count for assigning spring BP\nminCompleteDOYBP1 &lt;- 15\nmaxCompleteDOYBP1 &lt;- 175\nnumForCompleteBP1 &lt;- round( ( maxCompleteDOYBP1-minCompleteDOYBP1 ) * 0.9 )\n\n# Set range (dOY) and count for assigning fall BP\nminCompleteDOYBP3 &lt;- 225\nmaxCompleteDOYBP3 &lt;- 350\nnumForCompleteBP3 &lt;- round( ( maxCompleteDOYBP3-minCompleteDOYBP3 ) * 0.9 )\n\n# Number of days in a row that need to be within the CIs to get assigned synchronised (referred to as numForward range)\nnumForwardSpring &lt;- 10\nnumForwardFall   &lt;- 16\n\n# Loop through all sites\nfor (j in 1:nSites){\n  \n  #library(plyr)\n  \n  # Index current site\n  # ------------------\n  e1 &lt;- dat_index[dat_index$site_name == siteList[j],]\n\n  # Index spring range\n  # ------------------\n    e3Spring &lt;- e1[ e1$yday &gt;= minCompleteDOYBP1 & e1$yday &lt;= maxCompleteDOYBP1, ]\n    \n  # Empty out from previous run\n    completeYearsSpring &lt;- NULL \n  \n  # If statement to avoid error if e3Spring is empty\n  if ( !plyr::empty( e3Spring ) ) {  \n    \n    # Determine which years have complete records in spring\n      completeSpring &lt;- as.data.frame( table( e3Spring$year,is.na( e3Spring$tempc_mean ) ) )\n      incompleteYearsSpring &lt;- as.numeric(as.character(completeSpring$Var1[completeSpring$Var2 == 'FALSE' & completeSpring$Freq &lt;  numForCompleteBP1]))\n      completeYearsSpring &lt;-   as.numeric(as.character(completeSpring$Var1[completeSpring$Var2 == 'FALSE' & completeSpring$Freq &gt;= numForCompleteBP1]))\n  }\n  \n  # Index fall range\n  # ----------------\n    e3Fall &lt;- e1[ e1$yday &gt;= minCompleteDOYBP3 & e1$yday &lt;= maxCompleteDOYBP3, ]\n  \n  # Empty out from previous run \n  completeYearsFall &lt;- NULL\n    \n  # If statement to avoid error if e3Fall is empty\n    if ( !plyr::empty( e3Fall ) ) {\n    \n    # Determine which years have complete records in fall\n      completeFall &lt;- as.data.frame( table( e3Fall$year,is.na( e3Fall$tempc_mean ) ) )\n      incompleteYearsFall &lt;- as.numeric(as.character(completeFall$Var1[completeFall$Var2 == 'FALSE' & completeFall$Freq &lt;  numForCompleteBP3]))\n      completeYearsFall &lt;-   as.numeric(as.character(completeFall$Var1[completeFall$Var2 == 'FALSE' & completeFall$Freq &gt;= numForCompleteBP3]))\n    } \n  \n  # Years with either a complete spring or complete fall record\n    completeYearsSpringOrFall &lt;- unique(c(completeYearsSpring,completeYearsFall))\n    \n  # Loop through the years with at least one complete season\n    for (year in completeYearsSpringOrFall){ \n\n    # Print status\n    #print(c('BP 1 and 3',j,as.character(siteList[j]),year))\n    \n    # New column for selecting years with at least one complete season\n      breaks$springOrFallBPComplete[ breaks$year == year & breaks$site_name == siteList[j] ] &lt;- TRUE\n     \n    # Index the high and low quantiles calculated from the tempIndex\n    lo &lt;- breaks$quantileLo[breaks$year == year & breaks$site_name == siteList[j]] \n    hi &lt;- breaks$quantileHi[breaks$year == year & breaks$site_name == siteList[j]] \n    \n    # Index current year\n    eYear &lt;- e1[e1$year == year, ] \n\n    # Spring Breakpoint Calculation\n    # -----------------------------\n\n    # Create dataframe for calculating number of synchronized days in a row. \n    runsSpring &lt;- data.frame(array(NA,c(1,numForwardSpring)))\n    \n    # Only calculate if it is a complete season\n        if(year %in% completeYearsSpring){\n            \n      # Loop through approximate time forward until breakpoint in ascending water temp\n      for (i in min(eYear$yday):(200)){\n                \n        # From the current day, loop forward through the numForward range to determined which days are in sync\n        for (ii in 2:numForwardSpring ){\n          \n          # A 1 gets assigned if the moving mean of that day is within the CI range or \n          #     if the iteration falls out of the approximated range examined. If the moving\n          #     mean is outside of the range, it gets assigned a zero.\n          if( (i+ii-2) %in% eYear$yday ) {\n                  runsSpring[ i,ii ] &lt;- 1*((eYear$movingMean[ eYear$yday == (i+ii-2) ] &gt;= lo) & (eYear$movingMean[ eYear$yday == (i+ii-2) ] &lt;= hi))\n          } else (runsSpring[ i,ii ] &lt;- 1  )\n            \n                }# end numForward loop\n        \n        # Determine if all of the days in the numForward range are in sync. If all days within numForward\n        #   are in sync (assigned a 1), the product will be a 1, otherwise it is NA.\n                runsSpring[ i,1 ] &lt;- prod( runsSpring[ i, 2:numForwardSpring ] )\n        \n            }# End approximated seasonal loop\n      \n      # The first day where all of the days ahead of it are in sync (in the numForward range) will be the minimum day with a 1.\n      #   This day gets assigned the spring breakpoint\n            breaks$springBP[ breaks$year == year & breaks$site_name == siteList[j] ] &lt;- min(which(runsSpring[,1] == 1))\n            \n      # Fill in the complete springBP column\n      breaks$springBPComplete[ breaks$year == year & breaks$site_name == siteList[j] ] &lt;- TRUE\n        } #completeYearsSpring if statement\n    \n    \n    # Fall Breakpoint Calculation\n    # ---------------------------\n    \n    # Create dataframe for calculating number of days in a row within range\n    runsFall   &lt;- data.frame(array(NA,c(1,numForwardFall)))\n    \n    # Only calculate if it is a complete season\n      if(year %in% completeYearsFall){\n\n      # Determine the point to stop to keep from going past lower limit if dOY\n      stopLoop &lt;- max( c( minCompleteDOYBP3,min(eYear$yday)+numForwardFall + 1 ) )  \n            \n      # Loop through the approximate time backward until descending water temp\n      for (i in  max(eYear$yday):stopLoop){\n          \n        # From the current day, loop backward through the numForward range to determined which days are in sync\n                for (ii in 2:numForwardFall ){\n          \n          # A 1 gets assigned if the moving mean of that day is within the CI range or \n          #     if the iteration falls out of the approximated range examined. If the moving\n          #     mean is outside of the range, it gets assigned a zero.\n                  if( (i-ii+2) %in% eYear$yday ) { \n                      runsFall[ i,ii ] &lt;- 1*((eYear$movingMean[ eYear$yday == (i-ii+2) ] &gt;= lo) & (eYear$movingMean[ eYear$yday == (i-ii+2) ] &lt;= hi))\n                  } else(runsFall[ i,ii ] &lt;- 1 )\n          \n                }# end numForward loop\n        \n        # Determine if all of the days in the numForward range are in sync. If all days within numForward\n        #   are in sync (assigned a 1), the product will be a 1, otherwise it is NA.\n        runsFall[ i,1 ] &lt;- prod( runsFall[ i, 2:numForwardFall ] )\n            \n      }# End approximated seasonal loop\n      \n      # The last day where all of the days ahead of it are in sync (in the numForward range) will be the minimum day with a 1.\n      #   This day gets assigned the fall breakpoint\n            breaks$fallBP[ breaks$year == year & breaks$site_name == siteList[j] ] &lt;- max(which(runsFall[,1] == 1))\n            \n      # Fill in the complete fallBP column\n      breaks$fallBPComplete[ breaks$year == year & breaks$site_name == siteList[j] ] &lt;- TRUE\n\n        }   #completeYearsFall if statement\n    \n    } #completeYearsSpringOrFall loop\n  \n} #site loop\n\nhead(breaks)\n\n  year     site_name quantileLo quantileHi springBPComplete fallBPComplete\n1 2020   Avery Brook -0.4928280  0.4245787             TRUE           TRUE\n2 2021   Avery Brook -0.4853836  0.2876319             TRUE           TRUE\n3 2022   Avery Brook -0.4425745  0.1521084             TRUE           TRUE\n4 2023   Avery Brook -0.4431010  0.2761850             TRUE          FALSE\n5 2024   Avery Brook -0.4147228  0.0801055             TRUE           TRUE\n6 2017 BigCreekLower -0.4135217  0.7688442            FALSE          FALSE\n  springOrFallBPComplete springBP fallBP\n1                   TRUE       66    300\n2                   TRUE       93    304\n3                   TRUE       94    313\n4                   TRUE       79     NA\n5                   TRUE       97    282\n6                  FALSE       NA     NA\n\n\nFor sites that did not have enough data to calculate a breakpoint, use the mean breakpoint at the smallest scale that a mean exists (site or basin).\n\nCode# Calculate mean BPs across different scales\nmeanBPSite  &lt;- plyr::ddply(breaks, \"site_name\", summarise, meanSpringBPSite = mean(springBP, na.rm = T), meanFallBPSite = mean(fallBP, na.rm = T) )\nmeanBPBasin &lt;- plyr::ddply(breaks %&gt;% left_join(siteinfo %&gt;% select(site_name, basin)), \"basin\", summarise, meanSpringBPBasin = mean(springBP,na.rm=T), meanFallBPBasin = mean(fallBP,na.rm=T) )\n#meanBPHUC8  &lt;- ddply( breaks, .(HUC8) , summarise, meanSpringBPHUC8  = mean(springBP,na.rm=T), meanFallBPHUC8  = mean(fallBP,na.rm=T) )\n#meanBPHUC4  &lt;- ddply( breaks, .(HUC4) , summarise, meanSpringBPHUC4  = mean(springBP,na.rm=T), meanFallBPHUC4  = mean(fallBP,na.rm=T) )\n\n# Merge in mean BPs to \"breaks\"\nbreaks &lt;- merge( x = breaks, y = meanBPSite , by = 'site_name' , all.x = T, all.y = F, sort = F)\nbreaks &lt;- merge( x = breaks %&gt;% left_join(siteinfo %&gt;% select(site_name, basin)), y = meanBPBasin, by = 'basin', all.x = T, all.y = F, sort = F)\n#breaks &lt;- merge( x = breaks, y = meanBPHUC8 , by = 'HUC8' , all.x = T, all.y = F, sort = F)\n#breaks &lt;- merge( x = breaks, y = meanBPHUC4 , by = 'HUC4' , all.x = T, all.y = F, sort = F)\n\n# Add columns for final breakpoints\nbreaks$finalSpringBP  &lt;- NA\nbreaks$sourceSpringBP &lt;- NA\nbreaks$finalFallBP    &lt;- NA\nbreaks$sourceFallBP   &lt;- NA\n\n\n# Calculated BPs\n# --------------\n# Spring\nnewSpringBP &lt;- which(is.na(breaks$finalSpringBP) & !is.na(breaks$springBP) )\nbreaks$finalSpringBP [ newSpringBP ] &lt;- breaks$springBP[ newSpringBP ]\nbreaks$sourceSpringBP[ newSpringBP ] &lt;- 'directly calculated'\n\n#Fall\nnewFallBP &lt;- which(is.na(breaks$finalFallBP) & !is.na(breaks$fallBP) )\nbreaks$finalFallBP [ newFallBP ] &lt;- breaks$fallBP[ newFallBP ]\nbreaks$sourceFallBP[ newFallBP ] &lt;- 'directly calculated'\n\n\n# Site averaged BPs\n# -----------------\n# Spring\nsiteBP &lt;- which(is.na(breaks$finalSpringBP) & !is.na(breaks$meanSpringBPSite) )\nbreaks$finalSpringBP [ siteBP ] &lt;- breaks$meanSpringBPSite[ siteBP ]\nbreaks$sourceSpringBP[ siteBP ] &lt;- 'site mean'\n\n# Fall\nsiteBP &lt;- which(is.na(breaks$finalFallBP) & !is.na(breaks$meanFallBPSite) )\nbreaks$finalFallBP [ siteBP ] &lt;- breaks$meanFallBPSite[ siteBP ]\nbreaks$sourceFallBP[ siteBP ] &lt;- 'site mean'\n\n\n# Basin averaged BPs\n# ------------------\n# Spring\nbasinBP &lt;- which(is.na(breaks$finalSpringBP) & !is.na(breaks$meanSpringBPBasin) )\nbreaks$finalSpringBP [ basinBP ] &lt;- breaks$meanSpringBPBasin[ basinBP ]\nbreaks$sourceSpringBP[ basinBP ] &lt;- 'basin mean'\n\n# Fall\nbasinBP &lt;- which(is.na(breaks$finalFallBP) & !is.na(breaks$meanFallBPBasin) )\nbreaks$finalFallBP [ basinBP ] &lt;- breaks$meanFallBPBasin[ basinBP ]\nbreaks$sourceFallBP[ basinBP ] &lt;- 'basin mean'\n\n\nView final breakpoint data\n\nCodedatatable(breaks)\n\n\n\n\n\nWrite to file\n\nCode# Index the columns to save\nspringFallBPs &lt;- breaks[,c('basin', 'site_name', 'year', 'finalSpringBP', 'sourceSpringBP', 'finalFallBP', 'sourceFallBP','quantileLo','quantileHi')]\n\n# fix erroneous Rock Creek, Lodgepole Creek spring breakpoint\n# springFallBPs &lt;- read_csv(\"data/breakpoints.csv\")\nspringFallBPs &lt;- springFallBPs %&gt;% \n  mutate(finalSpringBP = ifelse(site_name == \"Rock Creek\", 111, finalSpringBP),\n         sourceSpringBP = ifelse(site_name == \"Rock Creek\", \"basin mean\", sourceSpringBP)) %&gt;% \n  mutate(finalSpringBP = ifelse(site_name == \"Lodgepole Creek\", 99, finalSpringBP),\n         sourceSpringBP = ifelse(site_name == \"Lodgepole Creek\", \"basin mean\", sourceSpringBP))\n\n# Save the output\nwrite_csv(springFallBPs, \"data/breakpoints.csv\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Breakpoints</span>"
    ]
  },
  {
    "objectID": "Breakpoints.html#plot-breakpoints",
    "href": "Breakpoints.html#plot-breakpoints",
    "title": "\n3  Breakpoints\n",
    "section": "\n3.3 Plot breakpoints",
    "text": "3.3 Plot breakpoints\nShow examples of the breakpoint calculations for one stream in each basin. Compare to Figure 3 in Letcher et al. (2016). Note, this doesn’t really work in the Donner-Blitzen, where temperature data during winter/the shoulder seasons is entirely unavailable…nothing to inform breakpoint estimatation outside of the middle 150 days of year.\nCreate plotting function\n\nCodeindexfun &lt;- function(site) {\n# thermographs\np1 &lt;- ggplot() +\n  geom_line(data = dat_index %&gt;% filter(site_name == site), aes(x = yday, y = tempc_mean)) +\n  geom_line(data = dat_index %&gt;% filter(site_name == site), aes(x = yday, y = air_temp_mean), color = \"red\") +\n  geom_vline(data = breaks %&gt;% filter(site_name == site), aes(xintercept = finalFallBP), color = \"blue\") +\n  geom_vline(data = breaks %&gt;% filter(site_name == site), aes(xintercept = finalSpringBP), color = \"blue\") +\n  facet_wrap(~year, nrow = 1) +\n  theme_bw() + theme(panel.grid = element_blank()) + \n  ylab(\"Temperature (deg. C)\") \n# temperature indices\np2 &lt;- ggplot() +\n  geom_point(data = dat_index %&gt;% filter(site_name == site), aes(x = yday, y = index)) +\n  geom_vline(xintercept = c(125,275), linetype = \"dashed\") +\n  geom_vline(data = breaks %&gt;% filter(site_name == site), aes(xintercept = finalFallBP), color = \"blue\") +\n  geom_vline(data = breaks %&gt;% filter(site_name == site), aes(xintercept = finalSpringBP), color = \"blue\") +\n  geom_hline(data = breaks %&gt;% filter(site_name == site), aes(yintercept = quantileLo), color = \"red\") +\n  geom_hline(data = breaks %&gt;% filter(site_name == site), aes(yintercept = quantileHi), color = \"red\") +\n  facet_wrap(~year, nrow = 1) +\n  theme_bw() + theme(panel.grid = element_blank()) + \n  ylim(-20,20) +\n  ylab(\"Temperature index\") \n# arrange figures\nreturn(ggarrange(p1, p2, ncol = 1))\n}\n\n\n\n\nAvery Brook, West Brook\nPaine Run 01\nStaunton River 02\nMcGee Creek Trib, Flathead\nDugout Creek, Yellowstone\nLeidy Creek, Snake\nLittle Blitzen River, Donner-Blitzen\n\n\n\n\nCodeindexfun(\"Avery Brook\")\n\n\n\n\n\n\n\n\n\n\nCodeindexfun(\"Paine Run 01\")\n\n\n\n\n\n\n\n\n\n\nCodeindexfun(\"Staunton River 02\")\n\n\n\n\n\n\n\n\n\n\nCodeindexfun(\"McGeeCreekTrib\")\n\n\n\n\n\n\n\n\n\n\nCodeindexfun(\"Dugout Creek\")\n\n\n\n\n\n\n\n\n\n\nCodeindexfun(\"Leidy Creek Mouth\")\n\n\n\n\n\n\n\n\n\n\nCodeindexfun(\"Little Blizten River NWIS\")\n\n\n\n\n\n\n\n\n\n\nPlot trends in spring and fall breakpoints (only those we directly calculated). We have a ~limited number of years and so this isn’t all that informative\n\nCodep1 &lt;- springFallBPs %&gt;%\n  filter(sourceSpringBP == \"directly calculated\") %&gt;%\n  ggplot(aes(x = year, y = finalSpringBP, color = basin)) +\n  geom_point(aes(color = basin)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  ylab(\"Spring breakpoint (day of year)\") +\n  theme_bw() + theme(panel.grid = element_blank())\n  \np2 &lt;- springFallBPs %&gt;%\n  filter(sourceSpringBP == \"directly calculated\") %&gt;%\n  ggplot(aes(x = year, y = finalFallBP, color = basin)) +\n  geom_point(aes(color = basin)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  ylab(\"Fall breakpoint (day of year)\") +\n  theme_bw() + theme(panel.grid = element_blank())\n\nggpubr::ggarrange(p1, p2, nrow = 1, common.legend = TRUE)\n\n\n\n\n\n\n\nTrends in length of synchronized period\n\nCodespringFallBPs %&gt;%\n  filter(sourceSpringBP == \"directly calculated\") %&gt;%\n  mutate(SynchLen = finalFallBP - finalSpringBP) %&gt;%\n  ggplot(aes(x = year, y = SynchLen, color = basin)) +\n  geom_point(aes(color = basin)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  ylab(\"Length of synchronized period (days)\") +\n  theme_bw() + theme(panel.grid = element_blank())",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Breakpoints</span>"
    ]
  },
  {
    "objectID": "FormatData.html",
    "href": "FormatData.html",
    "title": "\n4  Format Data\n",
    "section": "",
    "text": "4.1 Base data\nTemperature and flow data\nCodedat &lt;- read_csv(\"data/EcoDrought_FlowTempData_DailyWeekly_clean.csv\")\ndat\n\n# A tibble: 183,960 × 42\n   station_no site_name   site_id basin      subbasin region   lat  long elev_ft\n   &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 &lt;NA&gt;       Avery Brook &lt;NA&gt;    &lt;NA&gt;       &lt;NA&gt;     &lt;NA&gt;    NA    NA       NA \n 2 &lt;NA&gt;       Avery Brook &lt;NA&gt;    &lt;NA&gt;       &lt;NA&gt;     &lt;NA&gt;    NA    NA       NA \n 3 &lt;NA&gt;       Avery Brook &lt;NA&gt;    &lt;NA&gt;       &lt;NA&gt;     &lt;NA&gt;    NA    NA       NA \n 4 &lt;NA&gt;       Avery Brook &lt;NA&gt;    &lt;NA&gt;       &lt;NA&gt;     &lt;NA&gt;    NA    NA       NA \n 5 &lt;NA&gt;       Avery Brook &lt;NA&gt;    &lt;NA&gt;       &lt;NA&gt;     &lt;NA&gt;    NA    NA       NA \n 6 &lt;NA&gt;       Avery Brook &lt;NA&gt;    &lt;NA&gt;       &lt;NA&gt;     &lt;NA&gt;    NA    NA       NA \n 7 &lt;NA&gt;       Avery Brook &lt;NA&gt;    &lt;NA&gt;       &lt;NA&gt;     &lt;NA&gt;    NA    NA       NA \n 8 01171000   Avery Brook AB      West Brook West Br… Mass    42.4 -72.7    699.\n 9 01171000   Avery Brook AB      West Brook West Br… Mass    42.4 -72.7    699.\n10 01171000   Avery Brook AB      West Brook West Br… Mass    42.4 -72.7    699.\n# ℹ 183,950 more rows\n# ℹ 33 more variables: area_sqmi &lt;dbl&gt;, designation &lt;chr&gt;, date &lt;date&gt;,\n#   DischargeReliability &lt;dbl&gt;, TempReliability &lt;dbl&gt;, flow_mean &lt;dbl&gt;,\n#   flow_min &lt;dbl&gt;, flow_max &lt;dbl&gt;, tempc_mean &lt;dbl&gt;, tempc_min &lt;dbl&gt;,\n#   tempc_max &lt;dbl&gt;, flow_mean_filled &lt;dbl&gt;, flow_mean_cms &lt;dbl&gt;,\n#   flow_mean_filled_cms &lt;dbl&gt;, area_sqkm &lt;dbl&gt;, Yield_mm &lt;dbl&gt;,\n#   Yield_filled_mm &lt;dbl&gt;, flow_mean_7 &lt;dbl&gt;, flow_mean_filled_7 &lt;dbl&gt;, …\nFix basins and trim to focal variables.\nCodemysitebasins &lt;- dat %&gt;% \n  group_by(site_name) %&gt;% \n  summarize(basin = unique(basin),\n            lat = unique(lat), \n            long = unique(long), \n            elev_ft = unique(elev_ft),\n            area_sqmi = unique(area_sqmi)) %&gt;% \n  filter(!is.na(basin), !is.na(lat), !is.na(long), !is.na(elev_ft), !is.na(area_sqmi)) %&gt;% \n  mutate(basin = recode(basin, \"Shields River\" = \"Yellowstone\"))\n\ndat &lt;- dat %&gt;% \n  select(-c(basin, lat, long, elev_ft, area_sqmi)) %&gt;% \n  left_join(mysitebasins) %&gt;% \n  select(site_name, basin, lat, long, elev_ft, area_sqmi, date, yday, year, siteYear, \n         tempc_mean, tempc_min, tempc_max, flow_mean, Yield_mm, air_temp_mean, precip_mmday, swe_kgm2, daylength_sec, shortrad_wm2)\n\ndat\n\n# A tibble: 183,960 × 20\n   site_name basin   lat  long elev_ft area_sqmi date        yday  year siteYear\n   &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n 1 Avery Br… West…  42.4 -72.7    699.      2.83 2020-01-01     1  2020 Avery B…\n 2 Avery Br… West…  42.4 -72.7    699.      2.83 2020-01-02     2  2020 Avery B…\n 3 Avery Br… West…  42.4 -72.7    699.      2.83 2020-01-03     3  2020 Avery B…\n 4 Avery Br… West…  42.4 -72.7    699.      2.83 2020-01-04     4  2020 Avery B…\n 5 Avery Br… West…  42.4 -72.7    699.      2.83 2020-01-05     5  2020 Avery B…\n 6 Avery Br… West…  42.4 -72.7    699.      2.83 2020-01-06     6  2020 Avery B…\n 7 Avery Br… West…  42.4 -72.7    699.      2.83 2020-01-07     7  2020 Avery B…\n 8 Avery Br… West…  42.4 -72.7    699.      2.83 2020-01-08     8  2020 Avery B…\n 9 Avery Br… West…  42.4 -72.7    699.      2.83 2020-01-09     9  2020 Avery B…\n10 Avery Br… West…  42.4 -72.7    699.      2.83 2020-01-10    10  2020 Avery B…\n# ℹ 183,950 more rows\n# ℹ 10 more variables: tempc_mean &lt;dbl&gt;, tempc_min &lt;dbl&gt;, tempc_max &lt;dbl&gt;,\n#   flow_mean &lt;dbl&gt;, Yield_mm &lt;dbl&gt;, air_temp_mean &lt;dbl&gt;, precip_mmday &lt;dbl&gt;,\n#   swe_kgm2 &lt;dbl&gt;, daylength_sec &lt;dbl&gt;, shortrad_wm2 &lt;dbl&gt;\nCalculate lagged air temperature variables\nCode# ensure proper ordering\ndat &lt;- dat[order(dat$site_name, dat$year, dat$yday),]\n\n# calculate lagged air temp\ndat &lt;- dat %&gt;%\n  group_by(site_name) %&gt;%\n  mutate(air_temp_mean_lag1 = lag(air_temp_mean, 1),\n         air_temp_mean_lag2 = lag(air_temp_mean, 2)) %&gt;%\n  ungroup()\nBreakpoints\nCodespringFallBPs &lt;- read_csv(\"data/breakpoints.csv\") %&gt;% \n  mutate(basin = recode(basin, \"Shields River\" = \"Yellowstone\"))\nspringFallBPs\n\n# A tibble: 459 × 9\n   basin   site_name  year finalSpringBP sourceSpringBP finalFallBP sourceFallBP\n   &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;       \n 1 West B… Avery Br…  2020          66   directly calc…        300  directly ca…\n 2 West B… Avery Br…  2021          93   directly calc…        304  directly ca…\n 3 West B… Avery Br…  2022          94   directly calc…        313  directly ca…\n 4 West B… Avery Br…  2023          79   directly calc…        300. site mean   \n 5 West B… Avery Br…  2024          97   directly calc…        282  directly ca…\n 6 West B… Sanderso…  2019          83.2 site mean             300  site mean   \n 7 West B… Sanderso…  2020          66   directly calc…        301  directly ca…\n 8 West B… Sanderso…  2021          80   directly calc…        303  directly ca…\n 9 West B… Sanderso…  2022          94   directly calc…        313  directly ca…\n10 West B… Sanderso…  2023          78   directly calc…        302  directly ca…\n# ℹ 449 more rows\n# ℹ 2 more variables: quantileLo &lt;dbl&gt;, quantileHi &lt;dbl&gt;\nJoin temp/flow data with breakpoints and filter to days within synchronized period.\nCodedat_bp &lt;- dat %&gt;% \n  left_join(springFallBPs) %&gt;%\n  filter(yday &gt;= finalSpringBP & yday &lt;= finalFallBP)\ndat_bp\n\n# A tibble: 81,424 × 28\n   site_name basin   lat  long elev_ft area_sqkm date        yday  year siteYear\n   &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n 1 Avery Br… West…  42.4 -72.7    699.      7.34 2020-03-06    66  2020 Avery B…\n 2 Avery Br… West…  42.4 -72.7    699.      7.34 2020-03-07    67  2020 Avery B…\n 3 Avery Br… West…  42.4 -72.7    699.      7.34 2020-03-08    68  2020 Avery B…\n 4 Avery Br… West…  42.4 -72.7    699.      7.34 2020-03-09    69  2020 Avery B…\n 5 Avery Br… West…  42.4 -72.7    699.      7.34 2020-03-10    70  2020 Avery B…\n 6 Avery Br… West…  42.4 -72.7    699.      7.34 2020-03-11    71  2020 Avery B…\n 7 Avery Br… West…  42.4 -72.7    699.      7.34 2020-03-12    72  2020 Avery B…\n 8 Avery Br… West…  42.4 -72.7    699.      7.34 2020-03-13    73  2020 Avery B…\n 9 Avery Br… West…  42.4 -72.7    699.      7.34 2020-03-14    74  2020 Avery B…\n10 Avery Br… West…  42.4 -72.7    699.      7.34 2020-03-15    75  2020 Avery B…\n# ℹ 81,414 more rows\n# ℹ 18 more variables: tempc_mean &lt;dbl&gt;, tempc_min &lt;dbl&gt;, tempc_max &lt;dbl&gt;,\n#   flow_mean &lt;dbl&gt;, Yield_mm &lt;dbl&gt;, air_temp_mean &lt;dbl&gt;, precip_mmday &lt;dbl&gt;,\n#   swe_kgm2 &lt;dbl&gt;, daylength_sec &lt;dbl&gt;, shortrad_wm2 &lt;dbl&gt;,\n#   air_temp_mean_lag1 &lt;dbl&gt;, air_temp_mean_lag2 &lt;dbl&gt;, finalSpringBP &lt;dbl&gt;,\n#   sourceSpringBP &lt;chr&gt;, finalFallBP &lt;dbl&gt;, sourceFallBP &lt;chr&gt;,\n#   quantileLo &lt;dbl&gt;, quantileHi &lt;dbl&gt;\nShow the distribution of the number of temperature observations (non-NA) per site-year\nCodeobspersy &lt;- dat_bp %&gt;% group_by(siteYear) %&gt;% summarize(numobs = sum(!is.na(tempc_mean))) %&gt;% ungroup()\nobspersy %&gt;% ggplot() + geom_histogram(aes(x = numobs)) + theme_bw()\nDrop siteYears with less than 10 days of temperature observations\nCodedrops &lt;- obspersy %&gt;% filter(numobs &lt; 10)\ndat_bp &lt;- dat_bp %&gt;% filter(!siteYear %in% drops$siteYear)\nPlot temp data with LOESS to show seasonal hysteresis\nCodedat_bp %&gt;% \n  ggplot(aes(x = yday, y = tempc_mean)) + \n  geom_point(size = 0.1) +\n  facet_wrap(~factor(basin, levels = c(\"West Brook\", \"Staunton River\", \"Paine Run\", \"Flathead\", \"Yellowstone\", \"Snake River\", \"Donner Blitzen\"))) +\n  geom_smooth(color = \"red\", se = FALSE) +\n  theme_bw() #+ theme(panel.grid = element_blank())\nCreate dummy site and basin varibles (numeric for JAGS), and define “rowNum” variable to allow for identifying first rows and evaluation rows\nCode# arrange\ndat_bp &lt;- dat_bp %&gt;% arrange(basin, site_name, year, yday)\n\n# create tibbles of site and basin numeric codes\nsitecodes &lt;- tibble(site_name = unique(dat_bp$site_name), site_code = 1:length(unique(dat_bp$site_name)))\nbasincodes &lt;- tibble(basin = unique(dat_bp$basin), basin_code = 1:length(unique(dat_bp$basin)))\n\n# join to data\ndat_bp &lt;- dat_bp %&gt;%\n  left_join(sitecodes) %&gt;%\n  left_join(basincodes) %&gt;%\n  mutate(rowNum = 1:nrow(.))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Format Data</span>"
    ]
  },
  {
    "objectID": "FormatData.html#landscape-covariates",
    "href": "FormatData.html#landscape-covariates",
    "title": "\n4  Format Data\n",
    "section": "\n4.2 Landscape covariates",
    "text": "4.2 Landscape covariates\nTo do – derive additional landscape covariates presumed to affect stream temperature, or rather, mediate the relationship between stream and air temperature/flow (groundwater influence/pasta?, basin slope, lake area, percept forest cover, etc.)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Format Data</span>"
    ]
  },
  {
    "objectID": "FormatData.html#check-correlations",
    "href": "FormatData.html#check-correlations",
    "title": "\n4  Format Data\n",
    "section": "\n4.3 Check correlations",
    "text": "4.3 Check correlations",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Format Data</span>"
    ]
  },
  {
    "objectID": "FormatData.html#write-to-file",
    "href": "FormatData.html#write-to-file",
    "title": "\n4  Format Data\n",
    "section": "\n4.4 Write to file",
    "text": "4.4 Write to file\nWrite formatted data to file\n\nCodewrite_csv(dat_bp, \"data/EcoDrought_FlowTempData_formatted.csv\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Format Data</span>"
    ]
  },
  {
    "objectID": "ModelTemp.html",
    "href": "ModelTemp.html",
    "title": "\n5  ModelTemp\n",
    "section": "",
    "text": "5.1 Load data\nRestrict to West Brook, and standardize flow by site (not sure we actually want to do this, but for just for now, to repeat Ben’s work). Also set flow = NA to 0. Probably should change this to latent variable in model, especially when expanding to sites where flow data is more rare\nCodedat &lt;- read_csv(\"data/EcoDrought_FlowTempData_formatted.csv\") %&gt;% \n  filter(basin == \"Snake River\",\n         year == 2020) %&gt;%\n  mutate(Yield_mm_log = log(Yield_mm + 0.00001),\n         flow_mean_log = log(flow_mean + 0.00001),\n         rowNum = 1:nrow(.)) %&gt;%\n  #group_by(site_name) %&gt;%\n  mutate(z_Yield_mm_log = scale(Yield_mm_log, center = TRUE, scale = TRUE),\n         z_air_temp_mean = scale(air_temp_mean, center = TRUE, scale = TRUE)) %&gt;%\n  #ungroup() %&gt;%\n  mutate(z_Yield_mm_log = ifelse(is.na(z_Yield_mm_log), 0, z_Yield_mm_log),\n         site_code = as.numeric(as.factor(site_name)),\n         year_code = year - min(year) + 1) \ndat\n\n# A tibble: 1,570 × 36\n   site_name basin   lat  long elev_ft area_sqkm date        yday  year siteYear\n   &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n 1 Grizzly … Snak…  43.8 -110.   8340.      32.8 2020-05-05   126  2020 Grizzly…\n 2 Grizzly … Snak…  43.8 -110.   8340.      32.8 2020-05-06   127  2020 Grizzly…\n 3 Grizzly … Snak…  43.8 -110.   8340.      32.8 2020-05-07   128  2020 Grizzly…\n 4 Grizzly … Snak…  43.8 -110.   8340.      32.8 2020-05-08   129  2020 Grizzly…\n 5 Grizzly … Snak…  43.8 -110.   8340.      32.8 2020-05-09   130  2020 Grizzly…\n 6 Grizzly … Snak…  43.8 -110.   8340.      32.8 2020-05-10   131  2020 Grizzly…\n 7 Grizzly … Snak…  43.8 -110.   8340.      32.8 2020-05-11   132  2020 Grizzly…\n 8 Grizzly … Snak…  43.8 -110.   8340.      32.8 2020-05-12   133  2020 Grizzly…\n 9 Grizzly … Snak…  43.8 -110.   8340.      32.8 2020-05-13   134  2020 Grizzly…\n10 Grizzly … Snak…  43.8 -110.   8340.      32.8 2020-05-14   135  2020 Grizzly…\n# ℹ 1,560 more rows\n# ℹ 26 more variables: tempc_mean &lt;dbl&gt;, tempc_min &lt;dbl&gt;, tempc_max &lt;dbl&gt;,\n#   flow_mean &lt;dbl&gt;, Yield_mm &lt;dbl&gt;, air_temp_mean &lt;dbl&gt;, precip_mmday &lt;dbl&gt;,\n#   swe_kgm2 &lt;dbl&gt;, daylength_sec &lt;dbl&gt;, shortrad_wm2 &lt;dbl&gt;,\n#   air_temp_mean_lag1 &lt;dbl&gt;, air_temp_mean_lag2 &lt;dbl&gt;, finalSpringBP &lt;dbl&gt;,\n#   sourceSpringBP &lt;chr&gt;, finalFallBP &lt;dbl&gt;, sourceFallBP &lt;chr&gt;,\n#   quantileLo &lt;dbl&gt;, quantileHi &lt;dbl&gt;, site_code &lt;dbl&gt;, basin_code &lt;dbl&gt;, …\nView data",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>ModelTemp</span>"
    ]
  },
  {
    "objectID": "ModelTemp.html#load-data",
    "href": "ModelTemp.html#load-data",
    "title": "\n5  ModelTemp\n",
    "section": "",
    "text": "Distributions\nTime series\nAir temp x Flow\n\n\n\n\nCodeggpubr::ggarrange(dat %&gt;% ggplot(aes(x = air_temp_mean, color = site_name)) + geom_density() + theme_bw(),\n                  dat %&gt;% ggplot(aes(x = flow_mean_log, color = site_name)) + geom_density() + theme_bw(),\n                  dat %&gt;% ggplot(aes(x = Yield_mm_log, color = site_name)) + geom_density() + theme_bw(),\n                  common.legend = TRUE, legend = \"right\", ncol = 1)\n\n\n\n\n\n\n\n\n\n\nCodedat %&gt;% ggplot() +\n  geom_line(aes(date, air_temp_mean), color = \"red\") + \n  geom_line(aes(date, tempc_mean)) +\n  geom_line(aes(date, z_Yield_mm_log*10), color = 'blue') +\n  facet_wrap(~site_name)\n\n\n\n\n\n\n\n\n\n\nCodedat %&gt;% \n  filter(z_Yield_mm_log != 0) %&gt;%\n  ggplot(aes(x = z_air_temp_mean, y = z_Yield_mm_log)) + \n  geom_point() + \n  ggpubr::stat_cor(method = \"pearson\", label.x.npc = 0, label.y.npc = 0.1) +\n  facet_wrap(~site_name)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>ModelTemp</span>"
    ]
  },
  {
    "objectID": "ModelTemp.html#specify-jags-model",
    "href": "ModelTemp.html#specify-jags-model",
    "title": "\n5  ModelTemp\n",
    "section": "\n5.2 Specify JAGS model",
    "text": "5.2 Specify JAGS model\nSpecify model following Letcher et al. (2016). MODIFIED\n\nCodecat(\"model {\n\n    ###----------------- LIKELIHOOD -----------------###\n    \n    # Days without an observation on the previous day (first observation in a series)\n    # No autoregressive term\n    \n    for (i in 1:n){\n      temp[i] ~ dnorm(stream.mu[i], pow(sigma, -2)) \n      stream.mu[i] &lt;- trend[i]\n      trend[i] &lt;- inprod(B.site[site[i], ], X.site[i, ])\n      \n      #flow[firstObsRows[i]] ~ dnorm(0, pow(10, -2))\n      }\n    \n    # for (i in 1:nFirstObsRows){\n    #   temp[firstObsRows[i]] ~ dnorm(stream.mu[firstObsRows[i]], pow(sigma, -2)) \n    #   stream.mu[firstObsRows[i]] &lt;- trend[firstObsRows[i]]\n    #   trend[firstObsRows[i]] &lt;- inprod(B.0[], X.0[firstObsRows[i], ]) + inprod(B.site[site[firstObsRows[i]], ], X.site[firstObsRows[i], ]) #+ inprod(B.year[year[firstObsRows[i]], ], X.year[firstObsRows[i], ])\n    #   \n    #   #flow[firstObsRows[i]] ~ dnorm(0, pow(10, -2))\n    #   }\n    # \n    # # Days with an observation on the previous dat (all days following the first day)\n    # # Includes autoregressive term (ar1)\n    # \n    # for (i in 1:nEvalRows){ \n    #   temp[evalRows[i]] ~ dnorm(stream.mu[evalRows[i]], pow(sigma, -2))\n    #   stream.mu[evalRows[i]] &lt;- trend[evalRows[i]] + ar1[site[evalRows[i]]] * (temp[evalRows[i]-1] - trend[ evalRows[i]-1 ])\n    #   trend[evalRows[i]]  &lt;- inprod(B.0[], X.0[evalRows[i], ]) + inprod(B.site[site[evalRows[i]], ], X.site[evalRows[i], ]) #+ inprod(B.year[year[evalRows[i]], ], X.year[evalRows[i], ])\n    #   \n    #   #flow[evalRows[i]] ~ dnorm(0, pow(10, -2))\n    #   }\n    \n    \n    ###----------------- PRIORS ---------------------###\n    \n    # # ar1, hierarchical by site\n    # for (i in 1:nSite){\n    #   ar1[i] ~ dnorm(ar1Mean, pow(ar1SD,-2) ) T(-1,1)       \n    # }\n    # ar1Mean ~ dunif( -1,1 ) \n    # ar1SD ~ dunif( 0, 2 )\n\n    # model variance\n    sigma ~ dunif(0, 100)\n    \n    \n    # fixed effect coefficients\n    for (k in 1:nFixedCovs) {\n      B.0[k] ~ dnorm(0, pow(100, -2))\n      }\n    \n    \n    # SITE EFFECTS\n    for (k in 1:nRandCovs) {\n      for (i in 1:nSite) {\n        B.site[i,k] ~ dnorm(0, pow(10, -2))   \n      }\n    }\n    \n      \n    # # YEAR EFFECTS\n    # # Priors for random effects of year\n    # for (t in 1:Ti) { # Ti years\n    #   B.year[t, 1:L] ~ dmnorm(mu.year[ ], tau.B.year[ , ])\n    #   }\n    # \n    # mu.year[1] &lt;- 0\n    # \n    # for (l in 2:L) {\n    #   mu.year[l] ~ dnorm(0, 0.0001)\n    #   }\n    # \n    # # Prior on multivariate normal std deviation\n    # tau.B.year[1:L, 1:L] ~ dwish(W.year[ , ], df.year)\n    # df.year &lt;- L + 1\n    # sigma.B.year[1:L, 1:L] &lt;- inverse(tau.B.year[ , ])\n    # for (l in 1:L) {\n    #   for (l.prime in 1:L) {\n    #     rho.B.year[l, l.prime] &lt;- sigma.B.year[l, l.prime]/sqrt(sigma.B.year[l, l]*sigma.B.year[l.prime, l.prime])\n    #     }\n    #   sigma.b.year[l] &lt;- sqrt(sigma.B.year[l, l])\n    # }\n    \n    \n    ###----------------- DERIVED VALUES -------------###\n    \n    # residuals\n    # residuals[1] &lt;- 0 # hold the place. Not sure if this is necessary...\n    for (i in 1:n) {\n      residuals[i] &lt;- temp[i] - stream.mu[i]\n    }\n    \n    # variance of model predictions (fixed + random effects)\n    var_fit &lt;- (sd(stream.mu))^2 \n\n    # residual variance\n    var_res &lt;- (sd(residuals))^2\n\n    # calculate Bayesian R^2\n    R2 &lt;- var_fit / (var_fit + var_res)\n    \n    # Root mean squared error\n    rmse &lt;- sqrt(mean(residuals[]^2))\n    \n    }\", file = \"DailyTempModelJAGS_mod.txt\")\n\n\nStraight from Letcher et al (2016)\n\nCodecat(\"model {\n\n    ###----------------- LIKELIHOOD -----------------###\n    \n    # Days without an observation on the previous day (first observation in a series)\n    # No autoregressive term\n    \n    for (i in 1:nFirstObsRows){\n      temp[firstObsRows[i]] ~ dnorm(stream.mu[firstObsRows[i]], pow(sigma, -2)) \n      stream.mu[firstObsRows[i]] &lt;- trend[firstObsRows[i]]\n      trend[firstObsRows[i]] &lt;- inprod(B.0[], X.0[firstObsRows[i], ]) + inprod(B.year[year[firstObsRows[i]], ], X.year[firstObsRows[i], ])\n      }\n    \n    # Days with an observation on the previous dat (all days following the first day)\n    # Includes autoregressive term (ar1)\n    \n    for (i in 1:nEvalRows){ \n      temp[evalRows[i]] ~ dnorm(stream.mu[evalRows[i]], pow(sigma, -2))\n      stream.mu[evalRows[i]] &lt;- trend[evalRows[i]] + ar1[river[evalRows[i]]] * (temp[evalRows[i]-1] - trend[ evalRows[i]-1 ])\n      trend[evalRows[i]]  &lt;- inprod(B.0[], X.0[evalRows[i], ]) + inprod(B.year[year[evalRows[i]], ], X.year[evalRows[i], ])\n      }\n    \n    \n    ###----------------- PRIORS ---------------------###\n    \n    # ar1, hierarchical by site\n    for (i in 1:nRiver){\n      ar1[i] ~ dnorm(ar1Mean, pow(ar1SD,-2) ) T(-1,1)       \n    }\n    ar1Mean ~ dunif( -1,1 ) \n    ar1SD ~ dunif( 0, 2 )\n\n    # model variance\n    sigma ~ dunif(0, 100)\n    \n    \n    # fixed effect coefficients\n    for (k in 1:K.0) {\n      B.0[k] ~ dnorm(0, 0.001)\n      }\n      \n      \n    # YEAR EFFECTS\n    # Priors for random effects of year\n    for (t in 1:Ti) { # Ti years\n      B.year[t, 1:L] ~ dmnorm(mu.year[ ], tau.B.year[ , ])\n      }\n      \n    mu.year[1] &lt;- 0\n    \n    for (l in 2:L) {\n      mu.year[l] ~ dnorm(0, 0.0001)\n      }\n      \n    # Prior on multivariate normal std deviation\n    tau.B.year[1:L, 1:L] ~ dwish(W.year[ , ], df.year)\n    df.year &lt;- L + 1\n    sigma.B.year[1:L, 1:L] &lt;- inverse(tau.B.year[ , ])\n    for (l in 1:L) {\n      for (l.prime in 1:L) {\n        rho.B.year[l, l.prime] &lt;- sigma.B.year[l, l.prime]/sqrt(sigma.B.year[l, l]*sigma.B.year[l.prime, l.prime])\n        }\n      sigma.b.year[l] &lt;- sqrt(sigma.B.year[l, l])\n    }\n    \n    \n    ###----------------- DERIVED VALUES -------------###\n    residuals[1] &lt;- 0 # hold the place. Not sure if this is necessary...\n    for (i in 2:n) {\n      residuals[i] &lt;- temp[i] - stream.mu[i]\n    }\n    \n    }\", file = \"DailyTempModelJAGS_Letcher.txt\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>ModelTemp</span>"
    ]
  },
  {
    "objectID": "ModelTemp.html#organize-objects",
    "href": "ModelTemp.html#organize-objects",
    "title": "\n5  ModelTemp\n",
    "section": "\n5.3 Organize objects",
    "text": "5.3 Organize objects\nGet first observation indices and check that nFirstRowObs equals the number of unique site-years: must be TRUE!\n\nCode# row indices for first observation in each site-year\nfirstObsRows &lt;- unlist(dat %&gt;% \n  group_by(siteYear) %&gt;%\n  summarize(index = rowNum[min(which(!is.na(tempc_mean)))]) %&gt;%\n  ungroup() %&gt;% \n  select(index))\nnFirstObsRows &lt;- length(firstObsRows)\n\n# does the number of first observations match the number of site years?\nnFirstObsRows == length(unique(dat$siteYear))\n\n[1] TRUE\n\n\nGet row indices for all other observations\n\nCodeevalRows &lt;- unlist(dat %&gt;% filter(!rowNum %in% firstObsRows) %&gt;% select(rowNum))\nnEvalRows &lt;- length(evalRows)\n\n\nCollate JAGS data in a list\n\nCode# fixed effects\ndata.fixed &lt;- data.frame(intercept = 1,\n                         # air temperature\n                         airTemp = dat$air_temp_mean,\n                         airTempLag1 = dat$air_temp_mean_lag1,\n                         airTempLag2 = dat$air_temp_mean_lag2,\n                         # flow\n                         flow = dat$z_Yield_mm_log,\n                         # air temp x flow interaction\n                         airFlow = dat$air_temp_mean * dat$z_Yield_mm_log\n                         )\n\n# random site effects\n# data.random.sites &lt;- data.frame(intercept.site = 1,\n#                                 airTemp = dat$air_temp_mean)\ndata.random.sites &lt;- data.frame(intercept.site = 1,\n                                air = dat$z_air_temp_mean,\n                                flow = dat$z_Yield_mm_log,\n                                airflow = dat$z_air_temp_mean * dat$z_Yield_mm_log)\n\n# random year effects\ndata.random.years &lt;- data.frame(intercept.year = 1,\n                                doy = dat$yday,\n                                doy2 = dat$yday^2,\n                                doy3 = dat$yday^3)\nTi &lt;- length(unique(dat$year))\nL &lt;- dim(data.random.years)[2]\nW.year &lt;- diag(L)\n\n# combine data in a list\njags.data &lt;- list(\"temp\" = dat$tempc_mean,\n                  \"nFirstObsRows\" = nFirstObsRows,\n                  \"firstObsRows\" = firstObsRows,\n                  \"nEvalRows\" = nEvalRows,\n                  \"evalRows\" = evalRows,\n                  \"X.0\" = data.fixed,\n                  \"X.site\" = data.random.sites,\n                  \"X.year\" = data.random.years,\n                  \"nFixedCovs\" = dim(data.fixed)[2],\n                  \"nRandCovs\" = dim(data.random.sites)[2],\n                  \"site\" = dat$site_code,\n                  \"year\" = dat$year_code,\n                  \"nSite\" = length(unique(dat$site_code)),\n                  \"Ti\" = Ti,\n                  \"L\" = L,\n                  \"W.year\" = W.year,\n                  \"n\" = dim(dat)[1])\n\n\nParameters to monitor\n\nCode# parameters to monitor\njags.params &lt;- c(\"B.0\", \"B.site\", \"B.year\",\n                 \"ar1\", \"ar1Mean\", \"ar1SD\", \n                 \"mu.year\", \"sigma.b.year\",\n                 \"sigma\", \"residuals\", \"R2\", \n                 \"temp\", \"stream.mu\", \"rmse\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>ModelTemp</span>"
    ]
  },
  {
    "objectID": "ModelTemp.html#fit-model",
    "href": "ModelTemp.html#fit-model",
    "title": "\n5  ModelTemp\n",
    "section": "\n5.4 Fit model",
    "text": "5.4 Fit model\n\nCodefit2 &lt;- jags(data = jags.data, inits = NULL, parameters.to.save = jags.params, model.file = \"DailyTempModelJAGS_mod.txt\",\n            n.chains = 3, n.thin = 5, n.burnin = 500, n.iter = 2500, DIC = TRUE)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1066\n   Unobserved stochastic nodes: 547\n   Total graph size: 14190\n\nInitializing model\n\n\nGet MCMC samples and summary\n\nCodetop_mod &lt;- fit2\n# generate MCMC samples and store as an array\nmodelout &lt;- top_mod$BUGSoutput\nMcmcList &lt;- vector(\"list\", length = dim(modelout$sims.array)[2])\nfor(i in 1:length(McmcList)) { McmcList[[i]] = as.mcmc(modelout$sims.array[,i,]) }\n# rbind MCMC samples from 10 chains \nMcmcdat &lt;- rbind(McmcList[[1]], McmcList[[2]], McmcList[[3]])\nparam.summary &lt;- modelout$summary\nhead(param.summary)\n\n             mean        sd      2.5%       25%       50%      75%    97.5%\nB.0[1] -1.9175189  99.42027 -201.0615 -62.99248  2.553325 61.95781 185.5070\nB.0[2]  0.1982315 101.52811 -191.9918 -69.74105  2.680515 67.33220 198.9505\nB.0[3]  1.9210055  99.67558 -195.1760 -64.98358  2.285073 68.46909 202.1766\nB.0[4]  0.5549154 101.83930 -191.0458 -69.31937 -1.121739 66.11728 203.5661\nB.0[5] -0.1924557  99.78069 -185.2194 -71.17171 -1.218507 66.75643 203.9491\nB.0[6]  1.0493200  96.72869 -182.6250 -65.27186 -3.479752 65.71293 199.0732\n            Rhat n.eff\nB.0[1] 0.9998981  1200\nB.0[2] 1.0002323  1200\nB.0[3] 1.0010438  1200\nB.0[4] 1.0006115  1200\nB.0[5] 1.0009274  1200\nB.0[6] 1.0049042   480\n\n\nConvert to ggs object\n\nCodeggfit &lt;- ggs(as.mcmc(top_mod), keep_original_order = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>ModelTemp</span>"
    ]
  },
  {
    "objectID": "ModelTemp.html#model-diagnostics",
    "href": "ModelTemp.html#model-diagnostics",
    "title": "\n5  ModelTemp\n",
    "section": "\n5.5 Model diagnostics",
    "text": "5.5 Model diagnostics\n\n5.5.1 Convergence\nAny problematic R-hat values (&gt;1.01)?\n\nCodetop_mod$BUGSoutput$summary[,8][top_mod$BUGSoutput$summary[,8] &gt; 1.01]\n\n    B.site[3,2]    residuals[3]  residuals[312]  residuals[313]  residuals[342] \n       1.011105        1.010671        1.010310        1.010328        1.010352 \n residuals[450]  residuals[655] residuals[1025] residuals[1142]  stream.mu[342] \n       1.010176        1.012328        1.010501        1.013023        1.010352 \n stream.mu[358]  stream.mu[450]  stream.mu[483] stream.mu[1261]       temp[506] \n       1.013363        1.010305        1.010782        1.012365        1.059390 \n      temp[532]       temp[655]       temp[733]      temp[1043]      temp[1067] \n       1.010589        1.023328        1.018785        1.033900        1.011473 \n     temp[1413]      temp[1414]      temp[1415]      temp[1567]      temp[1568] \n       1.012579        1.016556        1.013009        1.015436        1.013152 \n\n\nView traceplots\n\nCodeMCMCtrace(top_mod, ind = TRUE, \n          params = c(\"B.site\", \"B.year\", \n                     #\"ar1\", \"ar1Mean\", \"ar1SD\", \"mu.year\", \"sigma.b.year\", \"B.0\", \n                     \"sigma\", \"R2\", \"rmse\"), pdf = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.5.2 Goodness of fit\nFormat observed and predicted values\n\nCodeMcmcdat &lt;- as_tibble(Mcmcdat)\n\n# subset expected and observed MCMC samples\nppdat_exp &lt;- as.matrix(Mcmcdat[,startsWith(names(Mcmcdat), \"stream.mu[\")])\nppdat_obs &lt;- as.matrix(Mcmcdat[,startsWith(names(Mcmcdat), \"temp[\")])\n\n\nBayesian p-value\n\nCodesum(ppdat_exp &gt; ppdat_obs) / (dim(ppdat_obs)[1]*dim(ppdat_obs)[2])\n\n[1] 0.4768519\n\n\n\n\nPP-check\nRMSE\nR-squared\n\n\n\n\nCodeppdat_obs_mean &lt;- apply(ppdat_obs, 2, mean)\nppdat_exp_mean &lt;- apply(ppdat_exp, 2, mean)\ntibble(obs = ppdat_obs_mean, exp = ppdat_exp_mean) %&gt;% \n  ggplot(aes(x = obs, y = exp)) + \n  geom_point(alpha = 0.1) + \n  # geom_smooth(method = \"lm\") +\n  geom_abline(intercept = 0, slope = 1, color = \"red\") + \n  theme_bw() + theme(panel.grid = element_blank()) +\n  xlab(\"Observed\") + ylab(\"Predicted\")\n\n\n\n\n\n\n\n\n\n\nCodemean(unlist(ggfit %&gt;% filter(Parameter == \"rmse\") %&gt;% select(value)))\n\n[1] 1.534933\n\nCodeggs_density(ggfit, \"rmse\") \n\n\n\n\n\n\n\n\n\n\nCodemean(unlist(ggfit %&gt;% filter(Parameter == \"R2\") %&gt;% select(value)))\n\n[1] 0.7865546\n\nCodeggs_density(ggfit, \"R2\") + xlim(0,1)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>ModelTemp</span>"
    ]
  },
  {
    "objectID": "ModelTemp.html#plot-model-output",
    "href": "ModelTemp.html#plot-model-output",
    "title": "\n5  ModelTemp\n",
    "section": "\n5.6 Plot model output",
    "text": "5.6 Plot model output\n\nCodemyparams &lt;- unique(ggfit$Parameter)\n\n\n\n5.6.1 Dot plots\n\n\nIntercepts\nSlopes: air temp.\nSlopes: flow\nSlopes: air x flow\n\n\n\n\nCodeggs_caterpillar(ggfit %&gt;% filter(Parameter %in% grep(glob2rx(\"B.site*1]\"), myparams, value = TRUE)), sort = FALSE)\n\n\n\n\n\n\n\n\n\n\nCodeggs_caterpillar(ggfit %&gt;% filter(Parameter %in% grep(glob2rx(\"B.site*2]\"), myparams, value = TRUE)), sort = FALSE)\n\n\n\n\n\n\n\n\n\n\nCodeggs_caterpillar(ggfit %&gt;% filter(Parameter %in% grep(glob2rx(\"B.site*3]\",), myparams, value = TRUE)), sort = FALSE) + xlim(-5,5)\n\n\n\n\n\n\n\n\n\n\nCodeggs_caterpillar(ggfit %&gt;% filter(Parameter %in% grep(glob2rx(\"B.site*4]\"), myparams, value = TRUE)), sort = FALSE) + xlim(-2.5,2.5)\n\n\n\n\n\n\n\n\n\n\nInteraction heat maps",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>ModelTemp</span>"
    ]
  }
]